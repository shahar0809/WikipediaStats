# WikiMedia Events Statistics Application
Gathering statistics from [WikiMedia EventStreams][EventStreams] using **Kafka Streams**. 
Exposing the statistics via a REST API (using Kafka-Streams Interactive-Queries), to be displayed on a React JS webserver, designed using Chakra-UI components.

[EventStreams]: https://stream.wikimedia.org/v2/ui/#/


## Query the API

- curl localhost:7000/api.wikiStats/v1/month/per-language/countPagesCreated
- curl localhost:7000/api.wikiStats/v1/month/per-userType/countPagesCreated

- curl localhost:7000/api.wikiStats/v1/week/per-language/English/mostActiveUsers 
- curl localhost:7000/api.wikiStats/v1/week/per-userType/English/mostActiveUsers 

---
# Running Locally
The only dependency for running this project is [Docker Compose][docker].

[docker]: https://docs.docker.com/compose/install/

Start the application components, by running the following commands:

## Kafka Cluster
**_NOTE:_**  Make sure docker daemon is running.
```sh
# start the local Kafka cluster (references 'scipts/' for topic creation)
$ docker-compose up

$ docker-compose exec kafka bash
$ kafka-configs --bootstrap-server localhost:9092 --alter --entity-type topics --entity-name WikiEvents --add-config max.message.bytes=100485880
```

## Kafka-Streams Client (Java)
**_NOTE:_**  **On Windows OS use gradlew.bat. On Linux OS use gradlew**
Now, to run the Kafka Streams application, simply run:

```sh
$ cd $OLDPWD/wikipedia-statistics

# build project
$ ./gradlew build

# run project
$ ./gradlew run --info

```


## Kafka Producer (Python)
```sh
$ cd ./wikipedia-statistics/src/main/python
# activate virtual env
$ source ./venv/Scripts/activate
$ # (only do it once) pip install -r requirements.txt
$ export PYTHONPATH="$(pwd)/venv/Lib/site-packages"
# activate WikiMedia's EventStreams Kafka-producer
$ python3 ./wikiEventProducer.py --bootstrap_server localhost:29092 --topic_name WikiEvents --events_to_produce 10
```


##  Web Server Displaying Wiki-Statistics (JavaScript) 
```sh
$ cd ./src/main/js/my_app

# Install dependencies
$ npm install

# Start the web-server
$ npm start
```
---
# Useful Resources
These have been a huge help for me:
- The book [Mastering Kafka Streams and ksqlDB][book] by Mitch Seymour.
- Introduction to Apache Kafka with Wikipediaâ€™s EventStreams service article on [Medium][medium].
- The Chakra-UI Open-Source template: [Horizon UI][Horizon UI].

[book]: https://www.kafka-streams-book.com/
[medium]: https://towardsdatascience.com/introduction-to-apache-kafka-with-wikipedias-eventstreams-service-d06d4628e8d9
[Horizon UI]: https://horizon-ui.com/

# Producing Test Data
Once kafka cluster is running, you can produce some test data. Example records are found at `data/`, and mounted as the start dir of the kafka container.
To produce data, run the following commands.

```sh
# log into the broker, which is where the kafka console scripts live
$ docker-compose exec kafka bash

# produce test data to WikiEvents topic
$ kafka-console-producer \
  --bootstrap-server localhost:29092 \
  --topic WikiEvents < wiki-recentChange-events.json
```

# Consuming the alerts
This Kafka Streams application writes to an `alerts` topic whenever a patient experiences a combination of symptoms that could indicate an infection (high heart rate and body temperature). After producing the test data, you can view the alerts that were generated by consuming from the `alerts` topic. The following command shows how to do that.

```sh
# log into the broker, which is where the kafka console scripts live
$ docker-compose exec kafka bash

# consume from the beginning of the alerts topic
$ kafka-console-consumer \
  --bootstrap-server localhost:29092 \
  --topic WikiEvents \
  --from-beginning
```

You should see an alert similar to the following (prettified for readability):

```json
{
  "heart_rate": 120,
  "body_temp": {
    "timestamp": "2020-11-23T09:03:06.500Z",
    "temperature": 101.2,
    "unit": "F"
  }
}
```




Our patient monitoring application also exposes patient heart rates using Kafka Streams' interactive queries feature. The API is listening on port `7000`. Note the following examples use `jq` to prettify the output. If you don't have `jq` installed, either [install it][jq] or remove that part of the command.

[jq]: https://stedolan.github.io/jq/download/

### Get the heart rate for all patients, grouped by window
```bash
curl localhost:7000/bpm/all
```

You should see some output like the following:
```json
{
  "[1@1606122120000/1606122180000]": 120
}
```

The cryptic looking format is actually a compound key, made up of the patient ID and the timerange that the patient's BPM was calculated over. More specifically, the above output translates to:

```json
{
  "[patient_id@time_start/time_end]": bpm
}
```

You could of course massage the output format a bit, but we'll leave that as an exercise to the reader :)

### Get the heart rate for a single patient, within a specific time range
The following query will execute a windowed range scan under the hood. You can replace `1/1606122180000/1606122240000` with any valid value included in the output of the `curl localhost:7000/bpm/all` query we executed above.

```bash
curl localhost:7000/bpm/range/1/1606122120000/1606122180000
```

You should see output similar to the following:

```json
[
  {
    "count": 120,
    "timestamp": "2020-11-23T09:02:00Z"
  }
]
```